<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Bing WebMaster -->
  <meta name="msvalidate.01" content="AB2FFF876C37F59D9121882CC8395DE5" />

  <title>Bootstrapping Kubernetes Clusters with kubeadm</title>
  <meta name="description" content="">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://blog.codefarm.me/2019/01/28/bootstrapping-kubernetes-clusters-with-kubeadm/">
  <link rel="alternate" type="application/rss+xml" title="CODE FARM" href="https://blog.codefarm.me/feed.xml">

  <!-- https://cdn.jsdelivr.net/gh/lurongkai/anti-baidu/js/anti-baidu-latest.min.js -->
<script type="text/javascript" src="/js/anti-baidu.min.js" charset="UTF-8"></script>

  
<!-- Google Analytics Website tracking -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-83971182-1', 'auto');
  ga('send', 'pageview');

</script>


  
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SN88FJ18E5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SN88FJ18E5');
</script>



</head>


  <body>

    <header class="site-header">

  <div class="wrapper">
    <h2 class="site-title">
      <a class="site-title" href="/">CODE FARM</a>
    </h2>

     <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
        <div class="trigger">
            <ul>
                <li><a href="/">home</a>
                <li><a href="/category">category</a>
                <li><a href="/tag">tag</a>
                <li><a href="/archive">archive</a>
                <li><a href="/about">about</a>
                <li><a href="https://resume.github.io/?qqbuby" target="_blank">R&eacute;sum&eacute;</a>
            </ul>
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Bootstrapping Kubernetes Clusters with kubeadm</h1>
    
    
    <p class="post-meta"><time datetime="2019-01-28T11:11:46+08:00" itemprop="datePublished">Dec 15, 2022</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Using <strong>kubeadm</strong>, you can create a minimum viable Kubernetes cluster that conforms to best practices. In fact, you can use kubeadm to set up a cluster that will pass the <a href="https://kubernetes.io/blog/2017/10/software-conformance-certification/">Kubernetes Conformance tests</a>. kubeadm also supports other cluster lifecycle functions, such as <a href="https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/">bootstrap tokens</a> and cluster upgrades.</p>
</div>
</div>
<div id="toc" class="toc">
<div id="toctitle"></div>
<ul class="sectlevel1">
<li><a href="#installing-kubeadm-and-container-runtime">1. Installing kubeadm and container runtime</a>
<ul class="sectlevel2">
<li><a href="#verify-the-mac-address-and-product_uuid-are-unique-for-every-node">1.1. Verify the MAC address and product_uuid are unique for every node</a></li>
<li><a href="#check-required-ports">1.2. Check required ports</a></li>
<li><a href="#installing-a-container-runtime">1.3. Installing a container runtime</a>
<ul class="sectlevel3">
<li><a href="#cri-version-support">1.3.1. CRI version support</a></li>
<li><a href="#install-and-configure-prerequisites">1.3.2. Install and configure prerequisites</a>
<ul class="sectlevel4">
<li><a href="#forwarding-ipv4-and-letting-iptables-see-bridged-traffic">1.3.2.1. Forwarding IPv4 and letting iptables see bridged traffic</a></li>
</ul>
</li>
<li><a href="#cgroup-drivers">1.3.3. Cgroup drivers</a>
<ul class="sectlevel4">
<li><a href="#cgroupfs-driver">1.3.3.1. cgroupfs driver</a></li>
<li><a href="#systemd-cgroup-driver">1.3.3.2. systemd cgroup driver</a></li>
</ul>
</li>
<li><a href="#container-runtimes">1.3.4. Container runtimes</a>
<ul class="sectlevel4">
<li><a href="#containerd">1.3.4.1. containerd</a></li>
<li><a href="#docker-engine">1.3.4.2. Docker Engine</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#installing-kubeadm-kubelet-and-kubectl">1.4. Installing kubeadm, kubelet and kubectl</a>
<ul class="sectlevel3">
<li><a href="#debian-based-distributions">1.4.1. Debian-based distributions</a></li>
<li><a href="#red-hat-based-distributions">1.4.2. Red Hat-based distributions</a></li>
<li><a href="#set-crictl-endpoint-of-cri-container-runtime-service">1.4.3. Set CRICTL endpoint of CRI container runtime service</a></li>
<li><a href="#configuring-a-cgroup-driver">1.4.4. Configuring a cgroup driver</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#creating-a-cluster-with-kubeadm">2. Creating a cluster with kubeadm</a>
<ul class="sectlevel2">
<li><a href="#preparing-the-required-container-images">2.1. Preparing the required container images</a></li>
<li><a href="#initializing-your-control-plane-node">2.2. Initializing your control-plane node</a></li>
<li><a href="#the-kubelet-drop-in-file-for-systemd">2.3. The kubelet drop-in file for systemd</a></li>
<li><a href="#configurations-for-local-ephemeral-storage">2.4. Configurations for local ephemeral storage</a></li>
<li><a href="#installing-a-pod-network-add-on">2.5. Installing a Pod network add-on</a></li>
<li><a href="#control-plane-node-isolation">2.6. Control plane node isolation</a></li>
<li><a href="#joining-your-nodes">2.7. Joining your nodes</a></li>
<li><a href="#remove-the-node">2.8. Remove the node</a></li>
</ul>
</li>
<li><a href="#installing-addons">3. Installing Addons</a>
<ul class="sectlevel2">
<li><a href="#metrics-server">3.1. Metrics Server</a></li>
<li><a href="#ingress-controllers">3.2. Ingress Controllers</a></li>
</ul>
</li>
<li><a href="#references">References</a></li>
</ul>
</div>
</div>
<div class="sect1">
<h2 id="installing-kubeadm-and-container-runtime">1. Installing kubeadm and container runtime</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>A compatible Linux host. The Kubernetes project provides generic instructions for Linux distributions based on Debian and Red Hat, and those distributions without a package manager.</p>
</li>
<li>
<p>2 GB or more of RAM per machine (any less will leave little room for your apps).</p>
</li>
<li>
<p>2 CPUs or more.</p>
</li>
<li>
<p>Full network connectivity between all machines in the cluster (public or private network is fine).</p>
</li>
<li>
<p>Unique hostname, MAC address, and product_uuid for every node.</p>
</li>
<li>
<p>Certain ports are open on your machines.</p>
</li>
<li>
<p>Swap disabled. You <strong>MUST</strong> disable swap in order for the kubelet to work properly.</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="verify-the-mac-address-and-product_uuid-are-unique-for-every-node">1.1. Verify the MAC address and product_uuid are unique for every node</h3>
<div class="ulist">
<ul>
<li>
<p>You can get the MAC address of the network interfaces using the command <code>ip link</code> or <code>ifconfig -a</code></p>
</li>
<li>
<p>The product_uuid can be checked by using the command <code>sudo cat /sys/class/dmi/id/product_uuid</code></p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">[x@node-2 ~]$</span><span class="w"> </span>ip <span class="nb">link </span>show ens32
<span class="gp">2: ens32: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;</span><span class="w"> </span>mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000
<span class="go">    link/ether 00:0c:29:f2:e6:ca brd ff:ff:ff:ff:ff:ff

</span><span class="gp">[x@node-2 ~]$</span><span class="w"> </span><span class="nb">sudo cat</span> /sys/class/dmi/id/product_uuid
<span class="go">44314D56-8B56-37B6-C94C-6A2D5FF2E6CA</span></code></pre>
</div>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="check-required-ports">1.2. Check required ports</h3>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Control plane</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 28.5714%;">
<col style="width: 28.5715%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Protocol</th>
<th class="tableblock halign-left valign-top">Direction</th>
<th class="tableblock halign-left valign-top">Port Range</th>
<th class="tableblock halign-left valign-top">Purpose</th>
<th class="tableblock halign-left valign-top">Used By</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6443</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubernetes API server</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TCP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2379-2380</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">etcd server client API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kube-apiserver, etcd</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TCP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10250</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubelet API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Self, Control plane</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TCP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10259</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kube-scheduler</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Self</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TCP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10257</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kube-controller-manager</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Self</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Worker node(s)</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 28.5714%;">
<col style="width: 28.5715%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Protocol</th>
<th class="tableblock halign-left valign-top">Direction</th>
<th class="tableblock halign-left valign-top">Port Range</th>
<th class="tableblock halign-left valign-top">Purpose</th>
<th class="tableblock halign-left valign-top">Used By</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TCP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10250</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kubelet API</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Self, Control plane</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TCP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inbound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">30000-32767</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NodePort Services</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>These <a href="https://kubernetes.io/docs/reference/networking/ports-and-protocols/">required ports</a> need to be open in order for Kubernetes components to communicate with each other. You can use tools like netcat to check if a port is open. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="go">nc 127.0.0.1 6443</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The pod network plugin you use may also require certain ports to be open.</p>
</div>
</div>
<div class="sect2">
<h3 id="installing-a-container-runtime">1.3. Installing a container runtime</h3>
<div class="paragraph">
<p>To run containers in Pods, Kubernetes uses a <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes">container runtime</a>.</p>
</div>
<div class="paragraph">
<p>By default, Kubernetes uses the <a href="https://kubernetes.io/docs/concepts/overview/components/#container-runtime">Container Runtime Interface</a> (CRI) to interface with your chosen container runtime.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Kubernetes 1.26 requires that you use a runtime that conforms with the <a href="https://kubernetes.io/docs/concepts/overview/components/#container-runtime">Container Runtime Interface</a> (CRI).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you don&#8217;t specify a runtime, kubeadm automatically tries to detect an installed container runtime by scanning through a list of known endpoints.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. Known endpoints for Linux supported operating systems</caption>
<colgroup>
<col style="width: 40%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Runtime</th>
<th class="tableblock halign-left valign-top">Path to Unix domain socket</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">containerd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">unix:///var/run/containerd/containerd.sock</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CRI-O</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">unix:///var/run/crio/crio.sock</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Docker Engine (using cri-dockerd)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">unix:///var/run/cri-dockerd.sock</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>If multiple or no container runtimes are detected kubeadm will throw an error and will request that you specify which one you want to use.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Docker Engine does not implement the <a href="https://kubernetes.io/docs/concepts/architecture/cri/">CRI</a> which is a requirement for a container runtime to work with Kubernetes. For that reason, an additional service <a href="https://github.com/Mirantis/cri-dockerd">cri-dockerd</a> has to be installed. cri-dockerd is a project based on the legacy built-in Docker Engine support that was removed from the kubelet in version 1.24.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="cri-version-support">1.3.1. CRI version support</h4>
<div class="paragraph">
<p>Your container runtime must support at least v1alpha2 of the container runtime interface.</p>
</div>
<div class="paragraph">
<p>Kubernetes 1.26 defaults to using v1 of the CRI API. If a container runtime does not support the v1 API, the kubelet falls back to using the (deprecated) v1alpha2 API instead.</p>
</div>
</div>
<div class="sect3">
<h4 id="install-and-configure-prerequisites">1.3.2. Install and configure prerequisites</h4>
<div class="paragraph">
<p>The following steps apply common settings for Kubernetes nodes on Linux.</p>
</div>
<div class="paragraph">
<p>You can skip a particular setting if you&#8217;re certain you don&#8217;t need it.</p>
</div>
<div class="sect4">
<h5 id="forwarding-ipv4-and-letting-iptables-see-bridged-traffic">1.3.2.1. Forwarding IPv4 and letting iptables see bridged traffic</h5>
<div class="paragraph">
<p>Verify that the <code>br_netfilter</code> module is loaded by running <code>lsmod | grep br_netfilter</code>.</p>
</div>
<div class="paragraph">
<p>To load it explicitly, run <code>sudo modprobe br_netfilter</code>.</p>
</div>
<div class="paragraph">
<p>In order for a Linux node&#8217;s iptables to correctly view bridged traffic, verify that <code>net.bridge.bridge-nf-call-iptables</code> is set to <code>1</code> in your <code>sysctl</code> config. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
</span><span class="no">EOF

</span><span class="nb">sudo </span>modprobe overlay
<span class="nb">sudo </span>modprobe br_netfilter

<span class="c"># sysctl params required by setup, params persist across reboots</span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
</span><span class="no">EOF

</span><span class="c"># Apply sysctl params without reboot</span>
<span class="nb">sudo </span>sysctl <span class="nt">--system</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="cgroup-drivers">1.3.3. Cgroup drivers</h4>
<div class="paragraph">
<p>On Linux, <a href="https://kubernetes.io/docs/reference/glossary/?all=true#term-cgroup">control groups</a> are used to constrain resources that are allocated to processes. <a href="#env-container-runtimes">[2]</a></p>
</div>
<div class="paragraph">
<p>Both kubelet and the underlying container runtime need to interface with control groups to enforce <a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">resource management for pods and containers</a> and set resources such as cpu/memory requests and limits.</p>
</div>
<div class="paragraph">
<p>To interface with control groups, the kubelet and the container runtime need to use a cgroup driver.</p>
</div>
<div class="paragraph">
<p>It&#8217;s critical that the kubelet and the container runtime uses the same cgroup driver and are configured the same.</p>
</div>
<div class="paragraph">
<p>There are two cgroup drivers available:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#cgroupfs-driver">cgroupfs</a></p>
</li>
<li>
<p><a href="#systemd-cgroup-driver">systemd</a></p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="cgroupfs-driver">1.3.3.1. cgroupfs driver</h5>
<div class="paragraph">
<p>The <strong>cgroupfs</strong> driver is the default cgroup driver in the kubelet. When the cgroupfs driver is used, the kubelet and the container runtime directly interface with the cgroup filesystem to configure cgroups.</p>
</div>
<div class="paragraph">
<p>The cgroupfs driver is <strong>not</strong> recommended when <a href="https://www.freedesktop.org/wiki/Software/systemd/">systemd</a> is the init system because systemd expects a single cgroup manager on the system.</p>
</div>
<div class="paragraph">
<p>Additionally, if you use <a href="https://kubernetes.io/docs/concepts/architecture/cgroups">cgroup v2</a> , use the <strong>systemd</strong> cgroup driver instead of cgroupfs.</p>
</div>
</div>
<div class="sect4">
<h5 id="systemd-cgroup-driver">1.3.3.2. systemd cgroup driver</h5>
<div class="paragraph">
<p>When <a href="https://www.freedesktop.org/wiki/Software/systemd/">systemd</a> is chosen as the init system for a Linux distribution, the init process generates and consumes a root control group (<em>cgroup</em>) and acts as a cgroup manager.</p>
</div>
<div class="paragraph">
<p>systemd has a tight integration with cgroups and allocates a cgroup per systemd unit. As a result, if you use systemd as the init system with the cgroupfs driver, the system gets two different cgroup managers.</p>
</div>
<div class="paragraph">
<p>Two cgroup managers result in two views of the available and in-use resources in the system.</p>
</div>
<div class="paragraph">
<p>In some cases, nodes that are configured to use cgroupfs for the kubelet and container runtime, but use systemd for the rest of the processes become unstable under resource pressure.</p>
</div>
<div class="paragraph">
<p>The approach to mitigate this instability is to use systemd as the cgroup driver for the kubelet and the container runtime when systemd is the selected init system.</p>
</div>
<div class="paragraph">
<p>To set <em>systemd</em> as the cgroup driver, edit the <a href="https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/">KubeletConfiguration</a> option of <code>cgroupDriver</code> and set it to systemd. For example:  <a href="#env-container-runtimes">[2]</a><a href="#cgroup-driver">[3]</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubelet.config.k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">KubeletConfiguration</span>
<span class="nn">...</span>
<span class="na">cgroupDriver</span><span class="pi">:</span> <span class="s">systemd</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
In v1.22, if the user is not setting the <code>cgroupDriver</code> field under <a href="https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/">KubeletConfiguration</a>, <em>kubeadm</em> will default it to <em>systemd</em>. <a href="#cgroup-driver">[3]</a>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="container-runtimes">1.3.4. Container runtimes</h4>
<div class="sect4">
<h5 id="containerd">1.3.4.1. containerd</h5>
<div class="paragraph">
<p>Follow the instructions for <a href="https://github.com/containerd/containerd/blob/main/docs/getting-started.md">getting started with containerd</a>. Return to this step once you&#8217;ve created a valid configuration file, <code>config.toml</code>.</p>
</div>
<div class="paragraph">
<p>You can find this file under the path <code>/etc/containerd/config.toml</code>.</p>
</div>
<div class="paragraph">
<p>On Linux the default CRI socket for containerd is <code>/run/containerd/containerd.sock</code>.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Configuring the systemd cgroup driver</strong></p>
<div class="paragraph">
<p>To use the <em>systemd</em> cgroup driver in <code>/etc/containerd/config.toml</code> with <em>runc</em>, set</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="toml"><span class="nn">[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]</span>
  <span class="err">...</span>
  <span class="nn">[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]</span>
    <span class="py">SystemdCgroup</span> <span class="p">=</span> <span class="kc">true</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The systemd cgroup driver is recommended if you use <a href="https://kubernetes.io/docs/concepts/architecture/cgroups">cgroup v2</a>.</p>
</div>
<div class="paragraph">
<p>The cgroup version depends on the Linux distribution being used and the default cgroup version configured on the OS.</p>
</div>
<div class="paragraph">
<p>To check which cgroup version your distribution uses, run the <code>stat -fc %T /sys/fs/cgroup/</code> command on the node: <a href="#cgroups">[4]</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">stat</span> <span class="nt">-fc</span> %T /sys/fs/cgroup/</code></pre>
</div>
</div>
<div class="paragraph">
<p>For cgroup v2, the output is <code>cgroup2fs</code>.</p>
</div>
<div class="paragraph">
<p>For cgroup v1, the output is <code>tmpfs</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you installed containerd from a package (for example, RPM or .deb), you may find that the CRI integration plugin is disabled by default.</p>
</div>
<div class="paragraph">
<p>You need CRI support enabled to use containerd with Kubernetes. Make sure that <em>cri</em> is not included in the <em>disabled_plugins</em> list within <em>/etc/containerd/config.toml</em>; if you made changes to that file, also restart <em>containerd</em>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>apt-get download containerd.io
<span class="go">Get:1 https://download.docker.com/linux/debian buster/stable amd64 containerd.io amd64 1.6.13-1 [27.7 MB]
Fetched 27.7 MB in 24s (1,154 kB/s)
</span><span class="gp">$</span><span class="w"> </span>dpkg <span class="nt">-c</span> containerd.io_1.6.13-1_amd64.deb
<span class="go">drwxr-xr-x root/root         0 2022-12-16 02:39 ./
drwxr-xr-x root/root         0 2022-12-16 02:39 ./etc/
drwxr-xr-x root/root         0 2022-12-16 02:39 ./etc/containerd/
-rw-r--r-- root/root       886 2022-12-16 02:39 ./etc/containerd/config.toml
</span><span class="c">....</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The follow configuration <em>/etc/containerd/config.toml</em> is used by Docker CE as default.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="toml"><span class="c">#   Copyright 2018-2022 Docker Inc.</span>

<span class="c">#   Licensed under the Apache License, Version 2.0 (the "License");</span>
<span class="c">#   you may not use this file except in compliance with the License.</span>
<span class="c">#   You may obtain a copy of the License at</span>

<span class="c">#       http://www.apache.org/licenses/LICENSE-2.0</span>

<span class="c">#   Unless required by applicable law or agreed to in writing, software</span>
<span class="c">#   distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="c">#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c">#   See the License for the specific language governing permissions and</span>
<span class="c">#   limitations under the License.</span>

<span class="hll"><span class="py">disabled_plugins</span> <span class="p">=</span> <span class="nn">["cri"]</span>
</span>
<span class="c">#root = "/var/lib/containerd"</span>
<span class="c">#state = "/run/containerd"</span>
<span class="c">#subreaper = true</span>
<span class="c">#oom_score = 0</span>

<span class="c">#[grpc]</span>
<span class="c">#  address = "/run/containerd/containerd.sock"</span>
<span class="c">#  uid = 0</span>
<span class="c">#  gid = 0</span>

<span class="c">#[debug]</span>
<span class="c">#  address = "/run/containerd/debug.sock"</span>
<span class="c">#  uid = 0</span>
<span class="c">#  gid = 0</span>
<span class="c">#  level = "info"</span></code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</li>
<li>
<p><strong>Overriding the sandbox (pause) image</strong></p>
<div class="paragraph">
<p>In your containerd config you can overwrite the sandbox image by setting the following config:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="toml"><span class="nn">[plugins."io.containerd.grpc.v1.cri"]</span>
  <span class="py">sandbox_image</span> <span class="p">=</span> <span class="s">"registry.k8s.io/pause:3.2"</span></code></pre>
</div>
</div>
</li>
<li>
<p><strong>Configure <em>root</em> and <em>state</em> storage locations</strong></p>
<div class="paragraph">
<p>In the containerd config file you will find settings for persistent and runtime storage locations as well as grpc, debug, and metrics addresses for the various APIs.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="toml"><span class="c">#root = "/var/lib/containerd"</span>
<span class="c">#state = "/run/containerd"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The containerd root will be used to store any type of persistent data for containerd. Snapshots, content, metadata for containers and image, as well as any plugin data will be kept in this location.</p>
</div>
<div class="paragraph">
<p>The root is also namespaced for plugins that containerd loads. Each plugin will have its own directory where it stores data. containerd itself does not actually have any persistent data that it needs to store, its functionality comes from the plugins that are loaded.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>tree  /var/lib/containerd/
<span class="go">/var/lib/containerd/
├── io.containerd.content.v1.content
│   └── ingest
├── io.containerd.metadata.v1.bolt
│   └── meta.db
├── io.containerd.runtime.v1.linux
├── io.containerd.runtime.v2.task
├── io.containerd.snapshotter.v1.btrfs
├── io.containerd.snapshotter.v1.native
│   └── snapshots
├── io.containerd.snapshotter.v1.overlayfs
│   └── snapshots
└── tmpmounts

11 directories, 1 file</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The containerd <em>state</em> will be used to store any type of ephemeral data. Sockets, pids, runtime state, mount points, and other plugin data that must not persist between reboots are stored in this location.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>tree /run/containerd/
<span class="go">/run/containerd/
├── containerd.sock
├── containerd.sock.ttrpc
├── io.containerd.runtime.v1.linux
└── io.containerd.runtime.v2.task

2 directories, 2 files</span></code></pre>
</div>
</div>
</li>
<li>
<p><strong>Configure HTTP or HTTPS proxy.</strong></p>
<div class="paragraph">
<p>The <em>contianerd</em> daemon uses the <em>HTTP_PROXY</em>, <em>HTTPS_PROXY</em>, and <em>NO_PROXY</em> environmental variables in its start-up environment to configure HTTP or HTTPS proxy behavior.</p>
</div>
<div class="openblock">
<div class="content">
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Create a systemd drop-in directory for the containerd service:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">sudo mkdir</span> <span class="nt">-p</span> /etc/systemd/system/containerd.service.d</code></pre>
</div>
</div>
</li>
<li>
<p>Create a file called <em>10-http_proxy.conf</em> at the above directory that adds the <em>HTTP_PROXY</em> environment variable:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="ini"><span class="nn">[Service]</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"HTTP_PROXY=http://proxy.example.com:80/"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Or, if you are behind an HTTPS proxy server, adds the <em>HTTPS_PROXY</em> environment variable:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="ini"><span class="nn">[Service]</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"HTTP_PROXY=http://proxy.example.com:80/"</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"HTTPS_PROXY=https://proxy.example.com:443/"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>If you have internal registries that you need to contact without proxying you can specify them via the <em>NO_PROXY</em> environment variable:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="ini"><span class="nn">[Service]</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"HTTP_PROXY=http://proxy.example.com:80/"</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"HTTPS_PROXY=https://proxy.example.com:443/"</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com"</span></code></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The <em>NO_PROXY</em> environment variable specifies URLs that should be excluded from proxying (on servers that should be contacted directly). This should be a comma-separated list of hostnames, domain names, or a mixture of both. Asterisks can be used as wildcards, but other clients may not support that. Domain names may be indicated by a leading dot. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="text">NO_PROXY="*.aventail.com,home.com,.seanet.com"</code></pre>
</div>
</div>
<div class="paragraph">
<p>says to contact all machines in the ‘aventail.com’ and ‘seanet.com’ domains directly, as well as the machine named ‘home.com’. If <em>NO_PROXY</em> isn’t defined, <em>no_PROXY</em> and <em>no_proxy</em> are also tried, in that order.</p>
</div>
<div class="paragraph">
<p>ref: <a href="https://www.gnu.org/software/emacs/manual/html_node/url/Proxies.html" class="bare">https://www.gnu.org/software/emacs/manual/html_node/url/Proxies.html</a></p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You can also use the <code>systemctl edit containerd</code> to edit <em>override.conf</em> at <em>/etc/systemd/system/containrd.service.d</em> for the containerd service.</p>
</div>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Flush changes and restart containerd:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>systemctl daemon-reload
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>systemctl restart containerd</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that the configuration has been loaded:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>systemctl show <span class="nt">--property</span><span class="o">=</span>Environment containerd <span class="nt">--full</span> <span class="nt">--no-pager</span></code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
</li>
</ol>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The <em>containerd.io</em> packages in DEB and RPM formats are distributed by Docker (not by the containerd project)</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Debian</strong></p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="c"># Update the apt package index and install packages to allow apt to use a repository over HTTPS</span>
<span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="se">\</span>
    ca-certificates <span class="se">\</span>
    curl <span class="se">\</span>
    gnupg <span class="se">\</span>
    lsb-release

<span class="c"># Add Docker’s official GPG key:</span>
<span class="nb">sudo mkdir</span> <span class="nt">-p</span> /etc/apt/keyrings
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/debian/gpg | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/docker.gpg

<span class="c"># Use the following command to set up the repository:</span>
<span class="nb">echo</span> <span class="se">\</span>
  <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian </span><span class="se">\</span><span class="s2">
  </span><span class="si">$(</span>lsb_release <span class="nt">-cs</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">sudo tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null

<span class="c"># Install containerd.io</span>
<span class="nb">sudo </span>apt-get update <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> containerd.io</code></pre>
</div>
</div>
</li>
<li>
<p><strong>CentOS</strong></p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="c"># Install the yum-utils package (which provides the yum-config-manager utility) and set up the repository.</span>
<span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> yum-utils
<span class="nb">sudo </span>yum-config-manager <span class="se">\</span>
    <span class="nt">--add-repo</span> <span class="se">\</span>
    https://download.docker.com/linux/centos/docker-ce.repo
<span class="c"># Install the latest version of containerd.</span>
<span class="c"># If prompted to accept the GPG key, verify that the fingerprint matches</span>
<span class="c"># `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`, and if so, accept it.</span>
<span class="nb">sudo </span>yum <span class="nb">install </span>containerd.io
<span class="c"># Start containerd.</span>
<span class="nb">sudo </span>systemctl <span class="nb">enable </span>containerd.service
<span class="nb">sudo </span>systemctl start containerd.service</code></pre>
</div>
</div>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>For more information about Cgroups, see <a href="/2021/11/23/linux-cgroups-containers/">Linux CGroups and Containers</a>.</p>
</div>
<div class="paragraph">
<p>For more information about containerd, see <a href="/2021/11/25/oci-runc-containerd-cri-dockershim/">RUNC CONTAINERD CRI DOCKERSHIM</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="docker-engine">1.3.4.2. Docker Engine</h5>
<div class="ulist">
<ul>
<li>
<p>On each of your nodes, install Docker for your Linux distribution as per <a href="https://docs.docker.com/engine/install/#server">Install Docker Engine</a>.</p>
</li>
<li>
<p>Install <a href="https://github.com/Mirantis/cri-dockerd">cri-dockerd</a>, following the instructions in that source code repository.</p>
<div class="paragraph">
<p>For <em>cri-dockerd</em>, the CRI socket is <em>/run/cri-dockerd.sock</em> by default.</p>
</div>
</li>
</ul>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This example sets the <em>cgroupdriver</em> to <em>systemd</em>: <a href="#docker-runtime-execution-options">[6]</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">sudo </span>sh <span class="nt">-c</span> <span class="s1">'cat &gt; /etc/docker/daemon.json &lt;&lt;EOF
{
  "data-root": "/var/lib/docker",
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF'</span></code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="installing-kubeadm-kubelet-and-kubectl">1.4. Installing kubeadm, kubelet and kubectl</h3>
<div class="paragraph">
<p>You will install these packages on all of your machines:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>kubeadm</strong>: the command to bootstrap the cluster.</p>
</li>
<li>
<p><strong>kubelet</strong>: the component that runs on all of the machines in your cluster and does things like starting pods and containers.</p>
</li>
<li>
<p><strong>kubectl</strong>: the command line util to talk to your cluster.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>kubeadm will not install or manage <em>kubelet</em> or <em>kubectl</em> for you, so you will need to ensure they match the version of the Kubernetes control plane you want kubeadm to install for you.</p>
</div>
<div class="paragraph">
<p>If you do not, there is a risk of a version skew occurring that can lead to unexpected, buggy behaviour.</p>
</div>
<div class="paragraph">
<p>However, one minor version skew between the kubelet and the control plane is supported, but the kubelet version may never exceed the API server version.</p>
</div>
<div class="paragraph">
<p>For example, the kubelet running <em>1.7.0</em> should be fully compatible with a <em>1.8.0</em> API server, but not vice versa.</p>
</div>
<div class="paragraph">
<p>For more information on version skews, see:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kubernetes <a href="https://kubernetes.io/docs/setup/release/version-skew-policy/">version and version-skew policy</a></p>
</li>
<li>
<p>Kubeadm-specific <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#version-skew-policy">version skew policy</a></p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="debian-based-distributions">1.4.1. Debian-based distributions</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Update the <em>apt</em> package index and install packages needed to use the Kubernetes <em>apt</em> repository:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt-get update
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> apt-transport-https ca-certificates curl</code></pre>
</div>
</div>
</li>
<li>
<p>Download the Google Cloud public signing key:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>curl <span class="nt">-fsSLo</span> /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg</code></pre>
</div>
</div>
</li>
<li>
<p>Add the Kubernetes <em>apt</em> repository:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main"</span> | <span class="nb">sudo tee</span> /etc/apt/sources.list.d/kubernetes.list</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note: You can also set the <em>kubernetes.list</em> repository with the following mirror by USTC China.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="c"># deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main</span>
deb <span class="o">[</span><span class="nb">arch</span><span class="o">=</span>amd64 signed-by<span class="o">=</span>/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://mirrors.ustc.edu.cn/kubernetes/apt/  kubernetes-xenial main</code></pre>
</div>
</div>
</li>
<li>
<p>Update <em>apt</em> package index, install <em>kubelet</em>, <em>kubeadm</em> and <em>kubectl</em>, and pin their version:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt-get update
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> kubelet kubeadm kubectl
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt-mark hold kubelet kubeadm kubectl</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also specify the installing package version:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>apt-cache madison kubeadm | <span class="nb">head</span> <span class="nt">-n</span> 5
<span class="go">   kubeadm |  1.26.0-00 | https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.25.5-00 | https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.25.4-00 | https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.25.3-00 | https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.25.2-00 | https://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial/main amd64 Packages

</span><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span>1.26.0-00 <span class="nv">kubeadm</span><span class="o">=</span>1.26.0-00 <span class="nv">kubectl</span><span class="o">=</span>1.26.0-00</code></pre>
</div>
</div>
</li>
<li>
<p>Output shell completion code for the specified shell (bash or zsh). <a href="#kubeadm_completion">[5]</a></p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="c"># Install the bash-completion framework</span>
<span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> bash-completion

<span class="c"># Output bash completion</span>
<span class="nb">sudo </span>sh <span class="nt">-c</span> <span class="s1">'kubeadm completion bash &gt; /etc/bash_completion.d/kubeadm'</span>
<span class="nb">sudo </span>sh <span class="nt">-c</span> <span class="s1">'kubectl completion bash &gt; /etc/bash_completion.d/kubectl'</span>
<span class="nb">sudo </span>sh <span class="nt">-c</span> <span class="s1">'crictl completion &gt; /etc/bash_completion.d/crictl'</span>

<span class="c"># Load the completion code for bash into the current shell</span>
<span class="nb">source</span> /etc/bash_completion</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>Set HTTP proxy for APT:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/apt/apt.conf.d/httproxy
&gt; Acquire::http::Proxy "http://PROXY_HOST:PORT";
&gt; EOF</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Here is a config <em>/etc/apt/apt.conf.d/10httproxy</em> file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="txt">Acquire::http::Proxy "http://10.20.30.40:1080";
Acquire::http::Proxy {
  # the special keyword DIRECT meaning to use no proxies
  #security.debian.org DIRECT;
  #security-cdn.debian.org DIRECT;
  ftp2.cn.debian.org DIRECT;
  ftp.cn.debian.org DIRECT;
  mirror.lzu.edu.cn DIRECT;
  mirrors.163.com DIRECT;
  mirrors.huaweicloud.com DIRECT;
  mirrors.tuna.tsinghua.edu.cn DIRECT;
  mirrors.ustc.edu.cn DIRECT;

  download.docker.com DIRECT;
  packages.microsoft.com DIRECT;
};</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="red-hat-based-distributions">1.4.2. Red Hat-based distributions</h4>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-</span><span class="se">\$</span><span class="sh">basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
</span><span class="no">EOF

</span><span class="c"># Set SELinux in permissive mode (effectively disabling it)</span>
<span class="nb">sudo </span>setenforce 0
<span class="nb">sudo sed</span> <span class="nt">-i</span> <span class="s1">'s/^SELINUX=enforcing$/SELINUX=permissive/'</span> /etc/selinux/config

<span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> kubelet kubeadm kubectl <span class="nt">--disableexcludes</span><span class="o">=</span>kubernetes

<span class="nb">sudo </span>systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet

<span class="c"># Install the bash-completion framework</span>
<span class="nb">sudo </span>yum <span class="nb">install</span> <span class="nt">-y</span> bash-completion

<span class="c"># Output bash completion</span>
<span class="nb">sudo </span>sh <span class="nt">-c</span> <span class="s1">'kubeadm completion bash &gt; /etc/bash_completion.d/kubeadm'</span>
<span class="nb">sudo </span>sh <span class="nt">-c</span> <span class="s1">'kubectl completion bash &gt; /etc/bash_completion.d/kubectl'</span>
<span class="nb">sudo </span>sh <span class="nt">-c</span> <span class="s1">'crictl completion &gt; /etc/bash_completion.d/crictl'</span>

<span class="c"># Load the completion code for bash into the current shell</span>
<span class="nb">source</span> /usr/share/bash-completion/bash_completion</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Setting SELinux in permissive mode by running <code>setenforce 0</code> and <code>sed &#8230;&#8203;</code> effectively disables it. This is required to allow containers to access the host filesystem, which is needed by pod networks for example. You have to do this until SELinux support is improved in the kubelet.</p>
</li>
<li>
<p>You can leave SELinux enabled if you know how to configure it but it may require settings that are not supported by kubeadm.</p>
</li>
<li>
<p>If the <code>baseurl</code> fails because your Red Hat-based distribution cannot interpret <code>basearch</code>, replace <code>\$basearch</code> with your computer&#8217;s architecture. Type <code>uname -m</code> to see that value. For example, the <code>baseurl</code> URL for <code>x86_64</code> could be: <code><a href="https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64" class="bare">https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</a></code></p>
</li>
<li>
<p>You can also replace the kubernetes repository with USTC China mirror. <a href="#rhel-7-yum-repo">[7]</a></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Update <code>/etc/yum.repos.d/kubernetes.repo</code>:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="ini"><span class="nn">[kubernetes]</span>
<span class="py">name</span><span class="p">=</span><span class="s">Kubernetes</span>
<span class="py">baseurl</span><span class="p">=</span><span class="s">https://mirrors.ustc.edu.cn/kubernetes/yum/repos/kubernetes-el7-</span><span class="se">\$</span><span class="s">basearch</span>
<span class="py">enabled</span><span class="p">=</span><span class="s">1</span>
<span class="py">gpgcheck</span><span class="p">=</span><span class="s">1</span>
<span class="py">gpgkey</span><span class="p">=</span><span class="s">https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span>
<span class="py">exclude</span><span class="p">=</span><span class="s">kubelet kubeadm kubectl</span></code></pre>
</div>
</div>
</li>
<li>
<p>You can install and import RPM GPG Key manually: <a href="#rpm-gpg-verify-packages">[8]</a></p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>curl <span class="nt">-fsSLo</span> /tmp/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>rpm <span class="nt">--import</span> /tmp/kubernetes-archive-keyring.gpg
<span class="go">
</span><span class="gp">$</span><span class="w"> </span>rpm <span class="nt">-qa</span> gpg-pubkey
<span class="go">gpg-pubkey-f4a80eb5-53a7ff4b
gpg-pubkey-3e1ba8d5-558ab6a8

</span><span class="gp">$</span><span class="w"> </span>rpm <span class="nt">-qi</span> gpg-pubkey-3e1ba8d5-558ab6a8
<span class="go">Version     : 3e1ba8d5
Release     : 558ab6a8
</span><span class="c">...
</span><span class="gp">Packager    : Google Cloud Packages RPM Signing Key &lt;gc-team@google.com&gt;</span><span class="w">
</span><span class="c">...</span></code></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You can also download the <a href="/assets/packages.cloud.google.com/yum/doc/rpm-package-key.gpg">rpm-package-key.gpg</a> here.</p>
</div>
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>You can also specify the installing package version:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>yum <span class="nt">--showduplicates</span> <span class="nt">--disableexcludes</span><span class="o">=</span>kubernetes list kubeadm | <span class="nb">tail</span> <span class="nt">-n</span> 5
<span class="go">kubeadm.x86_64                       1.25.2-0                        kubernetes
kubeadm.x86_64                       1.25.3-0                        kubernetes
kubeadm.x86_64                       1.25.4-0                        kubernetes
kubeadm.x86_64                       1.25.5-0                        kubernetes
kubeadm.x86_64                       1.26.0-0                        kubernetes

</span><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>yum <span class="nt">--disableexcludes</span><span class="o">=</span>kubernetes <span class="nb">install </span>kubelet-1.26.0-0 kubeadm-1.26.0-0 kubectl-1.26.0-0</code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>Set HTTP proxy for YUM:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">echo</span> <span class="s1">'proxy=http://PROXY_HOST:PORT'</span> <span class="o">&gt;&gt;</span> /etc/yum.conf</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here is a complete config <em>/etc/yum.repos.d/kubernetes.repo</em> file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="ini"><span class="nn">[kubernetes]</span>
<span class="py">name</span><span class="p">=</span><span class="s">Kubernetes</span>
<span class="py">baseurl</span><span class="p">=</span><span class="s">https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span>
<span class="py">enabled</span><span class="p">=</span><span class="s">1</span>
<span class="py">gpgcheck</span><span class="p">=</span><span class="s">1</span>
<span class="py">repo_gpgcheck</span><span class="p">=</span><span class="s">1</span>
<span class="py">gpgkey</span><span class="p">=</span><span class="s">https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span>
<span class="py">exclude</span><span class="p">=</span><span class="s">kube*</span>
<span class="py">proxy</span><span class="p">=</span><span class="s">http://10.20.30.40:1080/</span></code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="set-crictl-endpoint-of-cri-container-runtime-service">1.4.3. Set CRICTL endpoint of CRI container runtime service</h4>
<div class="paragraph">
<p>This example sets the container runtime endpoint of <em>crictl</em> as <code>unix:///run/containerd/containerd.sock</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">sudo </span>crictl config <span class="nt">--set</span> runtime-endpoint<span class="o">=</span>unix:///run/containerd/containerd.sock</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span><span class="nb">sudo cat</span> /etc/crictl.yaml
<span class="go">runtime-endpoint: "unix:///run/containerd/containerd.sock"
image-endpoint: ""
timeout: 0
debug: false
pull-image-on-create: false
disable-pull-on-run: false

</span><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>crictl info
<span class="go">
  "cniconfig": {
    "PluginDirs": [
      "/opt/cni/bin"
    ],
    "PluginConfDir": "/etc/cni/net.d",

  "config": {
    "containerd": {
      "runtimes": {
        "runc": {
          "options": {
            "SystemdCgroup": false

    "cni": {
      "binDir": "/opt/cni/bin",
      "confDir": "/etc/cni/net.d",
    },
    "sandboxImage": "registry.k8s.io/pause:3.6",

    "containerdRootDir": "/var/lib/containerd",
    "containerdEndpoint": "/run/containerd/containerd.sock",
    "rootDir": "/var/lib/containerd/io.containerd.grpc.v1.cri",
    "stateDir": "/run/containerd/io.containerd.grpc.v1.cri"
</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="configuring-a-cgroup-driver">1.4.4. Configuring a cgroup driver</h4>
<div class="paragraph">
<p>Both the container runtime and the kubelet have a property called "<a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">cgroup driver</a>", which is important for the management of cgroups on Linux machines.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Matching the container runtime and kubelet cgroup drivers is required or otherwise the kubelet process will fail.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To set <em>systemd</em> as the cgroup driver, edit the <em>KubeletConfiguration</em> option of <em>cgroupDriver</em> and set it to <em>systemd</em>. For example: <a href="#env-container-runtimes">[2]</a><a href="#cgroup-driver">[3]</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubelet.config.k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">KubeletConfiguration</span>
<span class="nn">...</span>
<span class="na">cgroupDriver</span><span class="pi">:</span> <span class="s">systemd</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
In v1.22, if the user is not setting the <em>cgroupDriver</em> field under <em>KubeletConfiguration</em>, <em>kubeadm</em> will default it to <em>systemd</em>.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="creating-a-cluster-with-kubeadm">2. Creating a cluster with kubeadm</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="preparing-the-required-container-images">2.1. Preparing the required container images</h3>
<div class="paragraph">
<p>This step is optional and only applies in case you wish <code>kubeadm init</code> and <code>kubeadm join</code> to not download the default container images which are hosted at <em>registry.k8s.io</em>.</p>
</div>
<div class="paragraph">
<p>Kubeadm has commands that can help you pre-pull the required images when <a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/#without-internet-connection">creating a cluster without an internet connection</a> on its nodes.</p>
</div>
<div class="paragraph">
<p>You can list and pull the images using the kubeadm config images sub-command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh">kubeadm config images list <span class="c"># [--kubernetes-version=v1.26.0] [--image-repository=registry.k8s.io]</span>
kubeadm config images pull <span class="c"># [--kubernetes-version=v1.26.0] [--image-repository=registry.k8s.io]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Kubeadm allows you to use a <a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init#custom-images">custom image repository</a> for the required images.</p>
</div>
<div class="paragraph">
<p>This example uses the custom image repository with  <em>registry.cn-hangzhou.aliyuncs.com/google_containers</em>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">sudo </span>kubeadm config images pull <span class="se">\</span>
  <span class="nt">--kubernetes-version</span><span class="o">=</span>v1.26.0 <span class="se">\</span>
  <span class="nt">--image-repository</span><span class="o">=</span>registry.cn-hangzhou.aliyuncs.com/google_containers</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can use <code>ctr</code> to retag the images back to the default repository <code>registry.k8s.io</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="c">#!/bin/sh</span>
<span class="nv">kubernetes_version</span><span class="o">=</span>v1.26.0
<span class="nv">image_repository</span><span class="o">=</span>registry.cn-hangzhou.aliyuncs.com/google_containers
<span class="nv">images</span><span class="o">=</span><span class="si">$(</span>kubeadm config images list <span class="se">\</span>
    <span class="nt">--kubernetes-version</span> <span class="nv">$kubernetes_version</span> <span class="se">\</span>
    <span class="nt">--image-repository</span> <span class="nv">$image_repository</span><span class="si">)</span>

<span class="k">for </span>i <span class="k">in</span> <span class="nv">$images</span><span class="p">;</span> <span class="k">do
    case</span> <span class="s2">"</span><span class="nv">$i</span><span class="s2">"</span> <span class="k">in</span>
        <span class="k">*</span>coredns<span class="k">*</span><span class="p">)</span>
            <span class="nv">new_repo</span><span class="o">=</span><span class="s2">"registry.k8s.io/coredns"</span>
            <span class="p">;;</span>
        <span class="k">*</span><span class="p">)</span>
            <span class="nv">new_repo</span><span class="o">=</span><span class="s2">"registry.k8s.io"</span>
            <span class="p">;;</span>
    <span class="k">esac</span>
    <span class="nv">newtag</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="s2">"</span><span class="nv">$i</span><span class="s2">"</span> | <span class="nb">sed</span> <span class="s2">"s@</span><span class="nv">$image_repository</span><span class="s2">@</span><span class="nv">$new_repo</span><span class="s2">@"</span><span class="si">)</span>
    ctr <span class="nt">-n</span> k8s.io images tag <span class="nv">$i</span> <span class="nv">$newtag</span>
<span class="k">done</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>You can override this behavior by using <a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file">kubeadm with a configuration file</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubeadm config print init-defaults
<span class="go">apiVersion: kubeadm.k8s.io/v1beta3
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 1.2.3.4
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
  imagePullPolicy: IfNotPresent
  name: node
  taints: null
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta3
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controllerManager: {}
dns: {}
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.k8s.io
kind: ClusterConfiguration
kubernetesVersion: 1.25.0
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
scheduler: {}</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="initializing-your-control-plane-node">2.2. Initializing your control-plane node</h3>
<div class="paragraph">
<p>The control-plane node is the machine where the control plane components run, including <a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/">etcd</a> (the cluster database) and the <a href="https://kubernetes.io/docs/concepts/overview/components/#kube-apiserver">API Server</a> (which the <a href="https://kubernetes.io/docs/user-guide/kubectl-overview/">kubectl</a> command line tool communicates with). <a href="#create-cluster-kubeadm">[9]</a></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>(Recommended) If you have plans to upgrade this single control-plane kubeadm cluster to high availability you should specify the <code>--control-plane-endpoint</code> to set the shared endpoint for all control-plane nodes. Such an endpoint can be either a DNS name or an IP address of a load-balancer.</p>
</li>
<li>
<p>Choose a <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network">Pod network</a> add-on, and verify whether it requires any arguments to be passed to <code>kubeadm init</code>. Depending on which third-party provider you choose, you might need to set the <code>--pod-network-cidr</code> to a provider-specific value.</p>
</li>
<li>
<p>(Optional) kubeadm tries to detect the container runtime by using a list of well known endpoints. To use different container runtime or if there are more than one installed on the provisioned node, specify the <code>--cri-socket</code> argument to kubeadm.</p>
</li>
<li>
<p>(Optional) Unless otherwise specified, kubeadm uses the network interface associated with the default gateway to set the advertise address for this particular control-plane node&#8217;s API server. To use a different network interface, specify the <code>--apiserver-advertise-address=&lt;ip-address&gt;</code> argument to kubeadm init. To deploy an IPv6 Kubernetes cluster using IPv6 addressing, you must specify an IPv6 address, for example <code>--apiserver-advertise-address=2001:db8::101</code>.</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>While <code>--apiserver-advertise-address</code> can be used to set the advertise address for this particular control-plane node&#8217;s API server, <code>--control-plane-endpoint</code> can be used to set the shared endpoint for all control-plane nodes.</p>
</div>
<div class="paragraph">
<p><code>--control-plane-endpoint</code> allows both IP addresses and DNS names that can map to IP addresses. Please contact your network administrator to evaluate possible solutions with respect to such mapping.</p>
</div>
<div class="paragraph">
<p>Here is an example mapping:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="text">192.168.0.102 cluster-endpoint</code></pre>
</div>
</div>
<div class="paragraph">
<p>Where <code>192.168.0.102</code> is the IP address of this node and cluster-endpoint is a custom DNS name that maps to this IP. This will allow you to pass <code>--control-plane-endpoint=cluster-endpoint</code> to <code>kubeadm init</code> and pass the same DNS name to <code>kubeadm join</code>. Later you can modify <code>cluster-endpoint</code> to point to the address of your load-balancer in an high availability scenario.</p>
</div>
<div class="paragraph">
<p>Turning a single control plane cluster created without <code>--control-plane-endpoint</code> into a highly available cluster is not supported by kubeadm.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="sh"><span class="nb">sudo </span>kubeadm init <span class="se">\</span>
    <span class="nt">--kubernetes-version</span><span class="o">=</span>v1.26.0 <span class="se">\</span>
    <span class="nt">--pod-network-cidr</span><span class="o">=</span>10.244.0.0/16 <span class="se">\</span>
    <span class="nt">--apiserver-advertise-address</span><span class="o">=</span>192.168.0.100 <span class="se">\</span>
    <span class="nt">--control-plane-endpoint</span><span class="o">=</span>cluster-endpoint <span class="se">\</span>
    <span class="nt">--ignore-preflight-errors</span><span class="o">=</span>NumCPU,Mem <span class="se">\</span>
    <span class="nt">--image-repository</span><span class="o">=</span>registry.cn-hangzhou.aliyuncs.com/google_containers <span class="se">\</span>
    <span class="nt">--dry-run</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="the-kubelet-drop-in-file-for-systemd">2.3. The kubelet drop-in file for systemd</h3>
<div class="paragraph">
<p><em>kubeadm</em> ships with configuration for how systemd should run the kubelet. Note that the kubeadm CLI command never touches this drop-in file. <a href="#kubeadm-kubelet-integration">[14]</a></p>
</div>
<div class="paragraph">
<p>This configuration file installed by the kubeadm <a href="https://github.com/kubernetes/release/blob/master/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf">DEB</a> or <a href="https://github.com/kubernetes/release/blob/master/cmd/kubepkg/templates/latest/rpm/kubeadm/10-kubeadm.conf">RPM</a> package is written to <em>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</em> and is used by systemd. It augments the basic <a href="https://github.com/kubernetes/release/blob/master/cmd/kubepkg/templates/latest/rpm/kubelet/kubelet.service">kubelet.service for RPM</a> or <a href="https://github.com/kubernetes/release/blob/master/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service">kubelet.service for DEB</a>:</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Note: The contents below are just an example.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="ini"><span class="nn">[Service]</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"</span>
<span class="c"># This is a file that "kubeadm init" and "kubeadm join" generate at runtime, populating
# the KUBELET_KUBEADM_ARGS variable dynamically
</span><span class="py">EnvironmentFile</span><span class="p">=</span><span class="s">-/var/lib/kubelet/kubeadm-flags.env</span>
<span class="c"># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably,
# the user should use the .NodeRegistration.KubeletExtraArgs object in the configuration files instead.
# KUBELET_EXTRA_ARGS should be sourced from this file.
</span><span class="py">EnvironmentFile</span><span class="p">=</span><span class="s">-/etc/default/kubelet</span>
<span class="py">ExecStart</span><span class="p">=</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This file specifies the default locations for all of the files managed by kubeadm for the kubelet.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The KubeConfig file to use for the TLS Bootstrap is <em>/etc/kubernetes/bootstrap-kubelet.conf</em>, but it is only used if <em>/etc/kubernetes/kubelet.conf</em> does not exist.</p>
</li>
<li>
<p>The KubeConfig file with the unique kubelet identity is <em>/etc/kubernetes/kubelet.conf</em>.</p>
</li>
<li>
<p>The file containing the kubelet&#8217;s ComponentConfig is <em>/var/lib/kubelet/config.yaml</em>.</p>
</li>
<li>
<p>The dynamic environment file that contains <em>KUBELET_KUBEADM_ARGS</em> is sourced from <em>/var/lib/kubelet/kubeadm-flags.env</em>.</p>
</li>
<li>
<p>The file that can contain user-specified flag overrides with <em>KUBELET_EXTRA_ARGS</em> is sourced from <em>/etc/default/kubelet</em> (for DEBs), or <em>/etc/sysconfig/kubelet</em> (for RPMs). <em>KUBELET_EXTRA_ARGS</em> is last in the flag chain and has the highest priority in the event of conflicting settings.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="configurations-for-local-ephemeral-storage">2.4. Configurations for local ephemeral storage</h3>
<div class="paragraph">
<p>Nodes have local ephemeral storage, backed by locally-attached writeable devices or, sometimes, by RAM. "Ephemeral" means that there is no long-term guarantee about durability. <a href="#manage-resources-containers">[13]</a> <a href="#so-ephemeral-storage">[15]</a></p>
</div>
<div class="paragraph">
<p>Pods use ephemeral local storage for scratch space, caching, and for logs. The kubelet can provide scratch space to Pods using local ephemeral storage to mount <a href="https://kubernetes.io/docs/concepts/storage/volumes/#emptydir">emptyDir</a> volumes into containers.</p>
</div>
<div class="paragraph">
<p>The kubelet also uses this kind of storage to hold node-level container logs, container images, and the writable layers of running containers.</p>
</div>
<div class="paragraph">
<p>Kubernetes supports two ways to configure local ephemeral storage on a node:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#local-storage-configurations-0">Single filesystem</a></p>
<div class="paragraph">
<p>In this configuration, you place all different kinds of ephemeral local data (emptyDir volumes, writeable layers, container images, logs) into one filesystem. The most effective way to configure the kubelet means dedicating this filesystem to Kubernetes (kubelet) data.</p>
</div>
<div class="paragraph">
<p>The kubelet also writes node-level container logs and treats these similarly to ephemeral local storage.</p>
</div>
<div class="paragraph">
<p>The kubelet writes logs to files inside its configured log directory (<em>/var/log</em> by default); and has a base directory for other locally stored data (<em>/var/lib/kubelet</em> by default).</p>
</div>
<div class="paragraph">
<p>Typically, both <em>/var/lib/kubelet</em> and <em>/var/log</em> are on the system root filesystem, and the kubelet is designed with that layout in mind.</p>
</div>
<div class="paragraph">
<p>Your node can have as many other filesystems, not used for Kubernetes, as you like.</p>
</div>
</li>
<li>
<p><a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#local-storage-configurations-1">Two filesystems</a></p>
<div class="paragraph">
<p>You have a filesystem on the node that you&#8217;re using for ephemeral data that comes from running Pods: logs, and emptyDir volumes. You can use this filesystem for other data (for example: system logs not related to Kubernetes); it can even be the root filesystem.</p>
</div>
<div class="paragraph">
<p>The kubelet also writes node-level container logs into the first filesystem, and treats these similarly to ephemeral local storage.</p>
</div>
<div class="paragraph">
<p>You also use a separate filesystem, backed by a different logical storage device. In this configuration, the directory where you tell the kubelet to place container image layers and writeable layers is on this second filesystem.</p>
</div>
<div class="paragraph">
<p>The first filesystem does not hold any image layers or writeable layers.</p>
</div>
<div class="paragraph">
<p>Your node can have as many other filesystems, not used for Kubernetes, as you like.</p>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>The kubelet can measure how much local storage it is using. It does this provided that you have set up the node using one of the supported configurations for local ephemeral storage.</p>
</div>
<div class="paragraph">
<p>If you have a different configuration, then the kubelet does not apply resource limits for ephemeral local storage.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Note: The kubelet tracks <em>tmpfs</em> emptyDir volumes as container memory use, rather than as local ephemeral storage.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Note: The kubelet will only track the root filesystem for ephemeral storage. OS layouts that mount a separate disk to <em>/var/lib/kubelet</em> or <em>/var/lib/containers</em> will not report ephemeral storage correctly.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="installing-a-pod-network-add-on">2.5. Installing a Pod network add-on</h3>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You must deploy a <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/">Container Network Interface</a> (CNI) based Pod network add-on so that your Pods can communicate with each other. Cluster DNS (CoreDNS) will not start up before a network is installed.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Take care that your Pod network must not overlap with any of the host networks: you are likely to see problems if there is any overlap. (If you find a collision between your network plugin&#8217;s preferred Pod network and some of your host networks, you should think of a suitable CIDR block to use instead, then use that during kubeadm init with <code>--pod-network-cidr</code> and as a replacement in your network plugin&#8217;s YAML).</p>
</li>
<li>
<p>By default, kubeadm sets up your cluster to use and enforce use of <a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">RBAC</a> (role based access control). Make sure that your Pod network plugin supports RBAC, and so do any manifests that you use to deploy it.</p>
</li>
<li>
<p>If you want to use IPv6&#8212;&#8203;either dual-stack, or single-stack IPv6 only networking&#8212;&#8203;for your cluster, make sure that your Pod network plugin supports IPv6. IPv6 support was added to CNI in v0.6.0.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Several external projects provide Kubernetes Pod networks using CNI, some of which also support <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">Network Policy</a>.</p>
</div>
<div class="paragraph">
<p>See a list of <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy">add-ons</a> that implement the <a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-networking-model">Kubernetes networking model</a>.</p>
</div>
<div class="paragraph">
<p>You can install a Pod network add-on with the following command on the control-plane node or a node that has the kubeconfig credentials:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubectl apply <span class="nt">-f</span> &lt;add-on.yaml&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can install only one Pod network per cluster.</p>
</div>
<div class="paragraph">
<p>Once a Pod network has been installed, you can confirm that it is working by checking that the CoreDNS Pod is Running in the output of <code>kubectl get pods --all-namespaces</code>. And once the CoreDNS Pod is up and running, you can continue by joining your nodes.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>Deploying flannel manually</strong><a href="#flannel">[10]</a></p>
</div>
<div class="paragraph">
<p>Flannel can be added to any existing Kubernetes cluster though it&#8217;s simplest to add <em>flannel</em> before any pods using the pod network have been started.</p>
</div>
<div class="paragraph">
<p>For Kubernetes v1.17+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/flannel-io/flannel/v0.20.2/Documentation/kube-flannel.yml</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you use custom podCIDR (not <em>10.244.0.0/16</em>) you first need to download the above manifest and modify the network to match your one.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="control-plane-node-isolation">2.6. Control plane node isolation</h3>
<div class="paragraph">
<p>By default, your cluster will not schedule Pods on the control plane nodes for security reasons. If you want to be able to schedule Pods on the control plane nodes, for example for a single machine Kubernetes cluster, run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubectl taint nodes <span class="nt">--all</span> node-role.kubernetes.io/control-plane-</code></pre>
</div>
</div>
<div class="paragraph">
<p>The output will look something like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="go">node/node-1.localdomain untainted
</span><span class="c">...</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This will remove the <code>node-role.kubernetes.io/control-plane:NoSchedule</code> taint from any nodes that have it, including the control plane nodes, meaning that the scheduler will then be able to schedule Pods everywhere.</p>
</div>
</div>
<div class="sect2">
<h3 id="joining-your-nodes">2.7. Joining your nodes</h3>
<div class="paragraph">
<p>The nodes are where your workloads (containers and Pods, etc) run. To add new nodes to your cluster do the following for each machine:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>SSH to the machine</p>
</li>
<li>
<p>Become root (e.g. <em>sudo su -</em>)</p>
</li>
<li>
<p>Install a runtime if needed</p>
</li>
<li>
<p>Run the command that was output by <em>kubeadm init</em>. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="go">You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and then running the following as root:

  kubeadm join cluster-endpoint:6443 --token r8zo5w.rfrg93x0luuo01cy \
	--discovery-token-ca-cert-hash sha256:ffede9eb2a183a66e3ba5dd313abe9423e36ee57ac3d6b75e7d693c3df3f23f1 \
	--control-plane

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join cluster-endpoint:6443 --token r8zo5w.rfrg93x0luuo01cy \
	--discovery-token-ca-cert-hash sha256:ffede9eb2a183a66e3ba5dd313abe9423e36ee57ac3d6b75e7d693c3df3f23f1</span></code></pre>
</div>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>If you do not have the token, you can get it by running the following command on the control-plane node:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubeadm token list
<span class="go">TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS
r8zo5w.rfrg93x0luuo01cy   23h         2022-12-27T06:07:36Z   authentication,signing   The default bootstrap token generated by 'kubeadm init'.   system:bootstrappers:kubeadm:default-node-token</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>By default, tokens expire after 24 hours. If you are joining a node to the cluster after the current token has expired, you can create a new token by running the following command on the control-plane node:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubeadm token create
<span class="go">jlur5d.5qzgyjl28ssfj3za</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>If you don&#8217;t have the value of <code>--discovery-token-ca-cert-hash</code>, you can get it by running the following command chain on the control-plane node:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>openssl x509 <span class="nt">-pubkey</span> <span class="nt">-in</span> /etc/kubernetes/pki/ca.crt | openssl rsa <span class="nt">-pubin</span> <span class="nt">-outform</span> der 2&gt;/dev/null | <span class="se">\</span>
<span class="go">   openssl dgst -sha256 -hex | sed 's/^.* //'
ffede9eb2a183a66e3ba5dd313abe9423e36ee57ac3d6b75e7d693c3df3f23f1</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also run the following command to create and print join command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubeadm token create <span class="nt">--print-join-command</span>
<span class="go">kubeadm join cluster-endpoint:6443 --token 2ihyt2.g933wbzyatjdw56i --discovery-token-ca-cert-hash sha256:ffede9eb2a183a66e3ba5dd313abe9423e36ee57ac3d6b75e7d693c3df3f23f1</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>As the cluster nodes are usually initialized sequentially, the CoreDNS Pods are likely to all run on the first control-plane node.</p>
</div>
<div class="paragraph">
<p>To provide higher availability, please rebalance the CoreDNS Pods with <code>kubectl -n kube-system rollout restart deployment coredns</code> after at least one new node is joined.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="remove-the-node">2.8. Remove the node</h3>
<div class="paragraph">
<p>Talking to the control-plane node with the appropriate credentials, run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubectl drain &lt;node name&gt; <span class="nt">--delete-emptydir-data</span> <span class="nt">--force</span> <span class="nt">--ignore-daemonsets</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Before removing the node, reset the state installed by kubeadm:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubeadm reset</code></pre>
</div>
</div>
<div class="paragraph">
<p>The reset process does not reset or clean up iptables rules or IPVS tables. If you wish to reset iptables, you must do so manually:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>iptables <span class="nt">-F</span> <span class="o">&amp;&amp;</span> iptables <span class="nt">-t</span> nat <span class="nt">-F</span> <span class="o">&amp;&amp;</span> iptables <span class="nt">-t</span> mangle <span class="nt">-F</span> <span class="o">&amp;&amp;</span> iptables <span class="nt">-X</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>If you want to reset the IPVS tables, you must run the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>ipvsadm <span class="nt">-C</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Now remove the node:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="console"><span class="gp">$</span><span class="w"> </span>kubectl delete node &lt;node name&gt;</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="installing-addons">3. Installing Addons</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="metrics-server">3.1. Metrics Server</h3>
<div class="paragraph">
<p><a href="https://github.com/kubernetes-sigs/metrics-server">Metrics Server</a> is a scalable, efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines. <a href="#bib-metrics-server">[11]</a></p>
</div>
<div class="paragraph">
<p>Metrics Server collects resource metrics from Kubelets and exposes them in Kubernetes apiserver through <a href="https://github.com/kubernetes/metrics">Metrics API</a> for use by <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler</a> and <a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/">Vertical Pod Autoscaler</a>.</p>
</div>
<div class="paragraph">
<p>Metrics API can also be accessed by <code>kubectl top</code>, making it easier to debug autoscaling pipelines.</p>
</div>
<div class="paragraph">
<p>Installation instructions can be found in <a href="https://github.com/kubernetes-sigs/metrics-server/releases">Metrics Server releases</a>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You can also consider updating the image as the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yml"><span class="c1"># kustomization.yaml</span>
<span class="na">resources</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">../base</span>
<span class="na">patchesStrategicMerge</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">metrics-server-deployment.yaml</span>
<span class="na">images</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">k8s.gcr.io/metrics-server/metrics-server</span>
    <span class="na">newName</span><span class="pi">:</span> <span class="s">registry.aliyuncs.com/google_containers/metrics-server</span></code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="ingress-controllers">3.2. Ingress Controllers</h3>
<div class="paragraph">
<p>In order for the Ingress resource to work, the cluster must have an ingress controller running. <a href="#bib-ingress-controllers">[12]</a></p>
</div>
<div class="paragraph">
<p>Kubernetes as a project supports and maintains <a href="https://github.com/kubernetes-sigs/aws-load-balancer-controller#readme">AWS</a>, <a href="https://git.k8s.io/ingress-gce/README.md#readme">GCE</a>, and <a href="https://git.k8s.io/ingress-nginx/README.md#readme">nginx</a> ingress controllers.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You can also consider updating the ingress-nginx images as the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yml"><span class="na">images</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">registry.k8s.io/ingress-nginx/controller</span>
    <span class="na">newName</span><span class="pi">:</span> <span class="s">registry.aliyuncs.com/google_containers/nginx-ingress-controller</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">registry.k8s.io/ingress-nginx/kube-webhook-certgen</span>
    <span class="na">newName</span><span class="pi">:</span> <span class="s">registry.aliyuncs.com/google_containers/kube-webhook-certgen</span></code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="references">References</h2>
<div class="sectionbody">
<div class="ulist bibliography">
<ul class="bibliography">
<li>
<p><a id="kubeadm"></a>[1] <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/" class="bare">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/</a></p>
</li>
<li>
<p><a id="env-container-runtimes"></a>[2] <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/" class="bare">https://kubernetes.io/docs/setup/production-environment/container-runtimes/</a></p>
</li>
<li>
<p><a id="cgroup-driver"></a>[3] <a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/" class="bare">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/</a></p>
</li>
<li>
<p><a id="cgroups"></a>[4] <a href="https://kubernetes.io/docs/concepts/architecture/cgroups/" class="bare">https://kubernetes.io/docs/concepts/architecture/cgroups/</a></p>
</li>
<li>
<p><a id="kubeadm_completion"></a>[5] <a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/generated/kubeadm_completion/" class="bare">https://kubernetes.io/docs/reference/setup-tools/kubeadm/generated/kubeadm_completion/</a></p>
</li>
<li>
<p><a id="docker-runtime-execution-options"></a>[6] <a href="https://docs.docker.com/engine/reference/commandline/dockerd/#docker-runtime-execution-options" class="bare">https://docs.docker.com/engine/reference/commandline/dockerd/#docker-runtime-execution-options</a></p>
</li>
<li>
<p><a id="rhel-7-yum-repo"></a>[7] <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/ch-yum#sec-Configuring_Yum_and_Yum_Repositories" class="bare">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/ch-yum#sec-Configuring_Yum_and_Yum_Repositories</a></p>
</li>
<li>
<p><a id="rpm-gpg-verify-packages"></a>[8] <a href="https://www.redhat.com/sysadmin/rpm-gpg-verify-packages" class="bare">https://www.redhat.com/sysadmin/rpm-gpg-verify-packages</a></p>
</li>
<li>
<p><a id="create-cluster-kubeadm"></a>[9] <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/" class="bare">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/</a></p>
</li>
<li>
<p><a id="flannel"></a>[10] <a href="https://github.com/flannel-io/flannel" class="bare">https://github.com/flannel-io/flannel</a></p>
</li>
<li>
<p><a id="bib-metrics-server"></a>[11] <a href="https://github.com/kubernetes-sigs/metrics-server" class="bare">https://github.com/kubernetes-sigs/metrics-server</a></p>
</li>
<li>
<p><a id="bib-ingress-controllers"></a>[12] <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/" class="bare">https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/</a></p>
</li>
<li>
<p><a id="manage-resources-containers"></a>[13] <a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/" class="bare">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</a></p>
</li>
<li>
<p><a id="kubeadm-kubelet-integration"></a>[14] <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/kubelet-integration/" class="bare">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/kubelet-integration/</a></p>
</li>
<li>
<p><a id="so-ephemeral-storage"></a>[15] <a href="https://stackoverflow.com/questions/70931881/what-does-kubelet-use-to-determine-the-ephemeral-storage-capacity-of-the-node" class="bare">https://stackoverflow.com/questions/70931881/what-does-kubelet-use-to-determine-the-ephemeral-storage-capacity-of-the-node</a></p>
</li>
</ul>
</div>
</div>
</div>
  </div>

  <ul class="post-navigation">
    <li>
      
      <a href="/2018/12/29/tcpdump-examples/">&laquo; Tcpdump Examples</a>
      
    </li>
    <li>
      
      <a href="/2019/01/31/public-key-cryptography-and-x509/">Cryptography and Public Key Infrastructure &raquo;</a>
      
    </li>
  </ul>
</article>

      </div>
    </div>

    <footer class="site-footer">
  <div class="license">
    <span>Article licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></span>
  </div>
  
  <details open>
    <summary>Extral Links</summary>
    <div>
      
      <a href="https://jekyllrb.com/">Jekyll</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://shopify.github.io/">Liquid</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://docs.asciidoctor.org/">Asciidoctor</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="https://github.com/qqbuby/">GitHub</a>
      
      &nbsp;.&nbsp;
      
      
      <a href="/feed.xml">RSS</a>
      
      
    </div>
  </details>
  
</footer>


<!-- https://github.com/bryanbraun/anchorjs -->
<script src="/js/anchor.min.js"></script>
<script>
  anchors.add();
  anchors.remove(".site-title");
</script>




  </body>

</html>
